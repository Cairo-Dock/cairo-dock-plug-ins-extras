#!/usr/bin/ruby

# This is a part of the external WebSearch applet for Cairo-Dock
#
# Author: Eduardo Mucelli Rezende Oliveira
# E-mail: edumucelli@gmail.com or eduardom@dcc.ufmg.br
#
# This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.

# This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.

# This applet provides an interface to some search engines such as Google, Bing, Teoma, Yahoo!, Youtube, Webshots, Flickr, and Wikipedia.
#	 To choose the search engine you can
#		(1) Right-click -> Configure this applet -> Configuration (tab) -> Search engine
#		(2) Scroll up or down over the icon (applicable only for the first search)
#    You can search in three ways
#		(1) Middle-click on the main icon
#		(2) Right-click on the main icon -> WebSearch -> (Choose the engine)
#		(3) Left-click on main icon (applicable only for the first search)
#    Type your query and validate. Each result will be shown as an sub-icon.
#	 Left-click to open the the result in the default web browser
# 	 Middle-click on the sub-icon of any result to show its description
#    Scroll up to fetch the next results
#	 Scroll down to fetch the previous results
#	 Left-click on the main icon to show search stats

%w{rubygems open-uri nokogiri dbus parseconfig launchy}.each { |x| require x }			# requirements

class Array
	def third
		self[2]																			# defining the method "third" just for code readability
	end
end

class String
	def to_b
		["true"].include?(self.downcase)												# string to boolean
	end
end

bus = DBus::SessionBus.instance															# TODO: a module to encapsulate DBus-Dock connection
applet_service = bus.service("org.cairodock.CairoDock")
applet_name = File.basename(Dir.getwd)													# nome do applet, neste caso é demo_ruby
applet_path = "/org/cairodock/CairoDock/#{applet_name}"									# caminho onde o objeto está guardado no bus
applet_object = applet_service.object(applet_path)
applet_object.introspect
applet_object.default_iface = 'org.cairodock.CairoDock.applet'							# list of icons contained in our sub-dock, or in our desklet

applet_sub_icons_object = applet_service.object("#{applet_path}/sub_icons")
applet_sub_icons_object.introspect
applet_sub_icons_object.default_iface = "org.cairodock.CairoDock.subapplet" 			# list of icons contained in our sub-dock, or in our desklet

class Link
	attr_accessor :url, :description, :id, :icon, :shortened_url
	@@next_id = 0																		# sequential id "static"

	def initialize (url = "", description = "", icon = File.expand_path("./icon"))
		self.url = url
		self.description = description
		self.id = @@next_id += 1
		self.icon = icon
		self.shortened_url = shorten url
	end

	def shorten (string, count = 45)													# TODO: count as a parameter in .conf file
		if string.length > count
			shortened = string.slice(0 .. count-1)
			shortened + "..." if shortened
		else
			string
		end
	end

	def self.reset_next_id
		class_variable_set(:@@next_id, 0)												# metaprogramming to reset the instance counter
	end
end

class ThumbnailedLink < Link															# a nice refactoring with the old YoutubeLink class
	attr_accessor :image_id, :thumb_url, :thumb_path, :downloaded_thumb
	@@next_image_id = 0

	def initialize(url = "", description = "", thumb_url = "")
		self.thumb_url = thumb_url
		self.image_id = @@next_image_id += 1
		self.thumb_path = define_thumbnail_path
		self.downloaded_thumb = false
		super(url, description)
	end

	def download_thumbnail
		# download thumb quietly (q), name it (O) '#{image_id}.jpg' and take it to the directory named as engine
		system("wget -q #{self.thumb_url} -O #{self.thumb_path}") 
		self.downloaded_thumb = true
		self.icon = File.expand_path(self.thumb_path)
	end

	# Thumbnail path composed by the search engine and image id
	def define_thumbnail_path
		directory = extract_directory_from_url
		"./images/#{directory}/#{self.image_id}.jpg"
	end	

	# Extract from the thumb_url the what is the search engine using the the core of the url
	def extract_directory_from_url
		directories = %w(youtube webshots flickr)										# directories names like engines names
		found = directories.detect {|d| self.thumb_url.include?(d)}						# search for engines names in thumb_url
	end

	def downloaded_thumb?
		self.downloaded_thumb
	end

	def self.reset_next_image_id
		class_variable_set(:@@next_image_id, 0)											# metaprogramming to reset the instance counter
	end
end

class Applet

	attr_accessor 	:engine, :links, :query, :stats, :engines, :file_name,
					:number_of_fetched_links, :number_of_displayed_links, :page_of_displayed_links, # prefetch works only for google
					:show_current_page, :show_description_instead_url, :show_thumbnail_preview,
					:scroll_engine_index

	Google = "http://www.google.com/search?q="											# (10,20,30,50,100) results per page
	Bing = "http://www.bing.com/search?q="												# 10 results per page
	Yahoo = "http://search.yahoo.com/search?p="											# 10 results per page
	Teoma = "http://www.teoma.com/web?q="												# 10 results per page
	Youtube = "http://www.youtube.com"
	YoutubeQ = "#{Youtube}/results?search_query="										# 20 results per page
	Webshots = "http://www.webshots.com/search?query="									# 72 results per page
	Flickr = "http://www.flickr.com"
	FlickrQ = "#{Flickr}/search/?q="													# 28 results per page
	Wikipedia = "http://en.wikipedia.org"
	WikipediaQ = "#{Wikipedia}/w/index.php?title=Special:Search&search="				# parameter "limit" results per page 

	DialogActiveTime = 5																# time in seconds the dialog window will be active

	def initialize applet, sub_icons, file_name
		self.query = ""
		self.file_name = file_name
		self.engines = [Google, Bing, Yahoo, Teoma, YoutubeQ, Webshots, FlickrQ, WikipediaQ]
		self.scroll_engine_index = 0													# current index when scrolling through search engines
		@icon = applet
		@sub_icons = sub_icons
		reset_search_settings
		set_configuration_parameters													# setting the self.configuration content
	end

	def set_configuration_parameters
		conf = ParseConfig.new(File.expand_path("~/.config/cairo-dock/current_theme/plug-ins/#{self.file_name}/#{self.file_name}.conf"))
		# for parameters within a list, the value is the position in the options list, not the value by itself
		self.engine = self.engines.at(conf.params['Configuration']['engine'].to_i)
		inform_current_search_engine													# inform in bottom of the icon what is the new engine
		self.number_of_fetched_links = [10, 20, 30, 50, 100].at(conf.params['Configuration']['number of fetched links'].to_i)
		self.number_of_displayed_links = conf.params['Configuration']['number of displayed links'].to_i # number of sub-icons to be shown
		self.show_current_page = conf.params['Configuration']['show current page'].to_b
		self.show_description_instead_url = conf.params['Configuration']['show description instead url'].to_b
		self.show_thumbnail_preview = conf.params['Configuration']['show thumbnail preview'].to_b
	end
	
	def start
		verify_user_action
	end

	def verify_user_action
		@icon.on_signal("on_build_menu") do |param|										# right click signal
			action_on_build_menu
		end
		@icon.on_signal("on_menu_select") do |selected_menu|
			action_on_menu_select selected_menu
		end
		@icon.on_signal("on_answer") do |answer|
			action_on_answer answer
		end
		@icon.on_signal("on_scroll") do |scroll_up|										# when the user scroll the mouse up or down on the icon
			action_on_scroll scroll_up													# scroll down param = false, scroll up param = true
		end
		@icon.on_signal("on_middle_click") do |param|
			ask_for_search_query
		end
		@icon.on_signal("on_click") do |param|
			action_on_click
		end
		@icon.on_signal("on_reload_module") do |config_has_changed|
			action_on_reload_module config_has_changed
		end
		@sub_icons.on_signal("on_click_sub_icon") do |param, sub_icon_id|
			action_on_click_sub_icon sub_icon_id
		end
		@sub_icons.on_signal("on_middle_click_sub_icon") do |sub_icon_id|
			action_on_middle_click_sub_icon sub_icon_id
		end
	end

	def action_on_build_menu
		#if @icon.add_menu_items_available											# Cairo-Dock > 2.1.4-0beta0
		# items = [{:type => 1, :label => 'Google', :menu => 0, :id => 1, :icon => './images/google.png', :tooltip => 'Google'}]
			# @icon.AddMenuItems(items)
		#else
		@icon.PopulateMenu(["Google", "Bing", "Yahoo!", "Teoma", "Youtube", "Webshots", "Flickr", "Wikipedia"])
		#end
	end

	def ask_for_search_query
		@icon.AskText("Search for:", "#{self.query}")
	end

	def action_on_answer answer
		unless answer.empty?
			reset_search_settings unless self.query.empty?
		    self.query = answer
			fetch_next_resulting_page
		end
	end

	def reset_search_settings
	    self.links = []
		self.stats = ""
		self.page_of_displayed_links = 0												# current pagination of displayed links
		Link.reset_next_id
	    ThumbnailedLink.reset_next_image_id
	    @sub_icons.RemoveSubIcon("any")
	end

	def action_on_click_sub_icon sub_icon_id
		Launchy.open self.links.at(sub_icon_id.to_i-1).url
	end

	def action_on_middle_click_sub_icon sub_icon_id
		text = ""
		if self.show_description_instead_url											# sub-icons are entitled by description ...
			text = self.links.at(sub_icon_id.to_i-1).url								# so URL will be shown in dialog
		else																			# sub-icons are entitled by url ...
			text = self.links.at(sub_icon_id.to_i-1).description						# so description will be shown in dialog
		end					
		@icon.ShowDialog(text, DialogActiveTime)
	end

	def action_on_click
		if self.query.empty?
			ask_for_search_query
		else
			@icon.ShowDialog(self.stats, DialogActiveTime) 
		end
	end

	# Changing the search engine by context menu
	def action_on_menu_select param
		switch_search_engine param
	end

	def action_on_reload_module config_has_changed
		set_configuration_parameters if config_has_changed
	end

	# Scrolling behavior can be switch the search engine, or fetch another resulting page
	def action_on_scroll scroll_up
		if self.query.empty?															# before the first query it is possible scroll through engines
			if scroll_up
				switch_search_engine self.scroll_engine_index +=1						# drawback: user scrolls a lot for up/down and this variable
			else																		# gets a value far from (0..self.engines.length-1) limits.
				switch_search_engine self.scroll_engine_index -=1						# user need to scroll back a lot to get in these limits again
			end
		else																			# later the first query scroll through the resulting pages
			if scroll_up
				fetch_next_resulting_page
			else
				fetch_previous_resulting_page
			end
		end
	end

	def switch_search_engine index
		index = 0 if index < 0															# keep the lower limit
		index = self.engines.length - 1 if index > self.engines.length - 1				# keep the upper limit
		self.engine = self.engines.at index
		reset_search_settings															# clean the previous search when choosing a new one
		inform_current_search_engine													# inform in the bottom of the icon what is the new engine
	end

	def fetch_next_resulting_page
		offset = self.page_of_displayed_links * self.number_of_displayed_links			# the position of the first link in the self.links array
		if self.links.size <= offset													# user already scrolled by the fetched links, fetch more
			inform_start_of_waiting_process
			case self.engine
				when Google; retrieve_links_from_google(self.query, offset)
				when Bing; 	 retrieve_links_from_bing(self.query, offset)
				when Yahoo;  retrieve_links_from_yahoo(self.query, offset)
				when Teoma;  retrieve_links_from_teoma(self.query, self.page_of_displayed_links + 1)	 	# first Teoma page is 1
				when YoutubeQ;  retrieve_links_from_youtube(self.query, self.page_of_displayed_links + 1) 	# first Youtube page is 1
				when Webshots;  retrieve_links_from_webshots(self.query, offset)
				when FlickrQ;  retrieve_links_from_flickr(self.query, self.page_of_displayed_links + 1)		# first Flickr page is 1
				when WikipediaQ;  retrieve_links_from_wikipedia(self.query, offset)
			end
			inform_end_of_waiting_process
        end
		self.page_of_displayed_links += 1												# sequential page identification, lets go to the next
		sub_icon_list = construct_sub_icon_list(offset)
		refresh_sub_icon_list (sub_icon_list)
		inform_current_page
	end

	# Since the previous results are already stored in self.links, it is necessary just to 
	# select the its interval that starts with the first link of the previous page.
	# An easier approach would be query google again with page-1 but it would result
	# more queries to the page, consequently it has some drawbacks such as increasing the 
	# probability of Google block the mechanized access, more bandwith, etc.
	def fetch_previous_resulting_page
		if self.page_of_displayed_links > 1												# there is no previous page from the first one
			self.page_of_displayed_links -= 1											# one page back
			inicio = (self.page_of_displayed_links-1) * self.number_of_displayed_links	# the first position of the link in the previous page
			sub_icon_list = construct_sub_icon_list(inicio)
			refresh_sub_icon_list (sub_icon_list)
		end
		inform_current_page
	end

	# Construct the menu using a set of fetched links
	# Links can have thumbnails
	def construct_sub_icon_list inicio
		sub_icon_list =[]
		inform_start_of_waiting_process
		threads =[]
		self.links[inicio, self.number_of_displayed_links].each do |link|				# first let's download the thumbs if necessary
			if link.instance_of?(ThumbnailedLink) and not link.downloaded_thumb?		# class that provides thumbs and a not yet downloaded thumb
				if self.show_thumbnail_preview 											# user want to see thumbs, so let's get it
					threads << Thread.new(link) do |l|									# parallelizing thumb download with multi-threading
						l.download_thumbnail
					end
				end
			end
		end
		threads.each { |t| t.join }
		self.links[inicio, self.number_of_displayed_links].each do |link|				# later, get the rest of sub-icons data
			if self.show_description_instead_url
				sub_icon_list << link.description										# user prefer see description with the sub-icon
			else
				sub_icon_list << link.shortened_url										# user prefer see shortened url with the sub-icon
			end
			sub_icon_list << link.icon													# the icon
			sub_icon_list << link.id.to_s												# the sequential id
		end
		inform_end_of_waiting_process
		sub_icon_list
	end

	def refresh_sub_icon_list sub_icon_list
		@sub_icons.RemoveSubIcon("any")													# remove all rendered sub-icons
		@sub_icons.AddSubIcons(sub_icon_list)
	end

    # Fetch a user-defined number links from Google with just one query. The parameter offset is the index of the first link.
    # It is better to fetch a higher amount of links in order to minimize the number of queries to be sent to google
	def retrieve_links_from_google(query, offset = 0)
		google = Nokogiri::HTML(open("#{Google}#{query}&start=#{offset}&num=#{self.number_of_fetched_links}"))
		self.stats = retrieve_google_result_stats(google)
		(google/"h3[@class='r']").search("a[@href]").each do |raw_link|
			url = raw_link['href']
			# Google "injects" its images results in the backlink-based results, desconsidering it
			unless url.include? "?q=#{query}"
				description = raw_link.inner_text
				self.links << Link.new(url, description)
			end
		end
	end

	# Retrieve informations from Google search stats
	# The stats array positions "Resultados first - second de aproximadamente third para fourth (fifth segundos)"
	def retrieve_google_result_stats google
		stats = (google/"p[@id='resultStats']/b").to_a
		total = stats.third.inner_text
		time = stats.last.inner_text
		"Search for #{self.query} returned #{total} results in #{time} seconds"
	end

	# Fetch links from Bing. Since Bing does not provide an in-url way to fetch more links than the 10
	# as Google does (&num=amount_to_fetch), this method will be called every time that 10 new results need to be shown
	def retrieve_links_from_bing(query, offset = 1)
		bing = Nokogiri::HTML(open("#{Bing}#{query}&first=#{offset}"))
		self.stats = retrieve_bing_result_stats(bing)
		(bing/"h3").search("a[@onmousedown]").each do |raw_link|
			url = raw_link['href']
			description = raw_link.inner_text
			self.links << Link.new(url, description)
		end
	end

	# Retrieve informations from Bing search stats	
	# The stats array postions "first-second 'of' third 'results'"
	def retrieve_bing_result_stats bing
		stats = (bing/"span[@id='count']").inner_text
		total = stats.split.third
		"Search for #{self.query} returned #{total} results"
	end

	# Fetch links from Yahoo!. Since Yahoo! does not provide an in-url way to fetch more links than the 10
	# as Google does (&num=amount_to_fetch), this method will be called every time that 10 new results need to be shown
	def retrieve_links_from_yahoo(query, offset = 1)
		yahoo = Nokogiri::HTML(open("#{Yahoo}#{query}&b=#{offset}"))
		self.stats = retrieve_yahoo_result_stats(yahoo)
		(yahoo/"div[@class~='res']").each do |res|					# divs are usually from 'res' class but some sub-results are 'res_indent' class
			url = (res/"span[@class='url']").inner_text
			description = (res/"h3/a").inner_text
			self.links << Link.new(url, description)
		end
	end

	# Retrieve informations from Yahoo! search stats	
	def retrieve_yahoo_result_stats yahoo
		total = (yahoo/"strong[@id='resultCount']").inner_text
		"Search for #{self.query} returned #{total} results"
	end
	
	# Instead of the offset (the index of the first link), Teoma (ask.com) receives the offset with the *page* value
	# The href paremeter has the URL and the tag's content has the description.
	# Teoma results are placed in an <a> tag with id='r(digit)_t'.
	def retrieve_links_from_teoma(query, page = 1)
		teoma = Nokogiri::HTML(open("#{Teoma}#{query}&page=#{page}"))
		self.stats = retrieve_teoma_result_stats teoma
		(teoma/"a[@id$='_t']").each do |res|											# any a tag with an id that ends with _t
			url = res['href']
			description = res.inner_text
			self.links << Link.new(url, description)
		end
	end

	def retrieve_teoma_result_stats teoma
		total = teoma.at("//span[@id='indexLast']").next.next.inner_text
		"Search for #{self.query} returned #{total} results"
	end

	# Fetch links from english Wikipedia. It is necessary to set user agent, or the connection is Forbidden (403)
	def retrieve_links_from_wikipedia(query, offset = 0)
		wikipedia = Nokogiri::HTML(open("#{WikipediaQ}#{query}&offset=#{offset}&limit=#{self.number_of_fetched_links}", 'User-Agent' => 'ruby'))
		self.stats = retrieve_webshots_result_wikipedia wikipedia
		(wikipedia/"ul[@class='mw-search-results']/li/a").each do |res|
			url = res['href']
			description = res['title']
			self.links << Link.new("#{Wikipedia}#{url}", description)
		end
	end

	def retrieve_webshots_result_wikipedia wikipedia
		total = wikipedia.at("div[@class='results-info']/ul/li/b").next.next.inner_text
		"Search for #{self.query} returned #{total} results"
	end

	# url, e.g, /watch?v=WwojCsQ3Fa8
	# thumb_url, e.g, "http://i4.ytimg.com/vi/WwojCsQ3Fa8/default.jpg"
	def retrieve_links_from_youtube(query, page = 1)
		youtube = Nokogiri::HTML(open("#{YoutubeQ}#{query}&page=#{page}"))
		self.stats = retrieve_youtube_result_stats youtube
		(youtube/"a[@id^='video-long-title-']").each do |res|							# 'a' tag has id which starts with "video-long-title-"
			url = res['href']
			description = res.inner_text
			video_id = url.split('=').last												# /watch?v=WwojCsQ3Fa8 => WwojCsQ3Fa8 => video_id
			thumb_url = "http://i4.ytimg.com/vi/#{video_id}/default.jpg"
			self.links << ThumbnailedLink.new("#{Youtube}#{url}", description, thumb_url)
		end
	end

	def retrieve_youtube_result_stats youtube
		total = youtube.at("div[@class='name']").inner_text.split.last
		"Search for #{self.query} returned #{total} results"
	end

	# url, e.g, http://good-times.webshots.com/photo/2500137270102572130
	# thumb_url, e.g, http://thumb10.webshots.net/t/24/665/1/37/27/2500137270102572130SmNoHt_th.jpg"
	def retrieve_links_from_webshots(query, offset = 0)
		webshots = Nokogiri::HTML(open("#{Webshots}#{query}&start=#{offset}"))
		self.stats = retrieve_webshots_result_stats webshots
		(webshots/"li[@onmouseover^='wsPopup']").each do |res|							# li tag has onmouseover which starts with "wsPopup"
			url = thumb_url = description = ""
			(res/"div[@class='photo']/a/img").each do |raw_thumb|
				thumb_url = raw_thumb['src']
			end
			(res/"div[@class='title']/p/a").each do |raw_link|
				url = raw_link['href']
				description = raw_link.inner_text
			end
			self.links << ThumbnailedLink.new(url, description, thumb_url)
		end
	end

	def retrieve_webshots_result_stats webshots
		total = webshots.at("div[@id='resultCount']/strong").inner_text
		"Search for #{self.query} returned #{total} results"
	end

	# url, e.g., /photos/21078069@N03/2780732654/
	# thumb_url, e.g., http://farm4.static.flickr.com/3255/2780732654_b7cbb2fb98_t.jpg"
	def retrieve_links_from_flickr(query, page = 1)
		flickr = Nokogiri::HTML(open("#{FlickrQ}#{query}#page=#{page}"))
		(flickr/"span[@class='photo_container pc_t']/a").each do |res|
			url = res['href']
			description = res['title']
			thumb_url = res.at("img")['src']
			self.links << ThumbnailedLink.new("#{Flickr}#{url}", description, thumb_url)
		end
	end

	def inform_start_of_waiting_process
		@icon.SetQuickInfo("...")
	end

	def inform_end_of_waiting_process
		@icon.SetQuickInfo("")
	end

	def inform_current_page
		if self.show_current_page
			@icon.SetQuickInfo("#{self.page_of_displayed_links}")
		else
			@icon.SetQuickInfo("")
		end
	end
	
	# Inform in the bottom of the icon what is new search engine
	def inform_current_search_engine
		current = case self.engine
			when Google; "Google"
			when Bing; "Bing"
			when Yahoo; "Yahoo!"
			when Teoma; "Teoma"
			when YoutubeQ; "Youtube"
			when Webshots; "Webshots"
			when FlickrQ; "Flickr"
			when WikipediaQ; "Wikipedia"
		end
 		@icon.SetQuickInfo(current)
	end
end

applet = Applet.new applet_object, applet_sub_icons_object, applet_name
applet.start
loop = DBus::Main.new
loop << bus
loop.run
